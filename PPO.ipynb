{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Union, Tuple, Callable, Optional\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "from flax.training.train_state import TrainState\n",
    "import optax\n",
    "\n",
    "from qdax import environments, environments_v1\n",
    "from jax import random\n",
    "\n",
    "import pickle\n",
    "from optax import exponential_decay\n",
    "from IPython.display import HTML\n",
    "from brax.io import html\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(env_name):\n",
    "    if env_name == \"hopper_uni\":\n",
    "        episode_length = 1000\n",
    "        \n",
    "        env = environments_v1.create(env_name, episode_length=episode_length)\n",
    "    elif env_name == \"halfcheetah_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length)\n",
    "        \n",
    "    elif env_name == \"walker2d_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length)\t\n",
    "    elif env_name == \"ant_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length, use_contact_forces=False, exclude_current_positions_from_observation=True)\n",
    "    elif env_name == \"humanoid_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length, exclude_current_positions_from_observation=True)\t\n",
    "    '''\n",
    "    elif env_name == \"ant_omni\":\n",
    "        episode_length = 250\n",
    "        max_bd = 30.\n",
    "\n",
    "        env = environments.create(env_name, episode_length=episode_length, use_contact_forces=False, exclude_current_positions_from_observation=False)\t\n",
    "    elif env_name == \"humanoid_uni\":\n",
    "        episode_length = 1000\n",
    "        max_bd = 1.\n",
    "\n",
    "        env = environments.create(env_name, episode_length=episode_length)\t\n",
    "    else:\n",
    "        ValueError(f\"Environment {env_name} not supported.\")\n",
    "    '''\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-8\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"MCPG MLP module\"\"\"\n",
    "    hidden_layers_size: Tuple[int, ...]\n",
    "    action_size: int\n",
    "    activation: Callable[[jnp.ndarray], jnp.ndarray] = nn.tanh\n",
    "    bias_init: Callable[[jnp.ndarray, Any], jnp.ndarray] = jax.nn.initializers.zeros\n",
    "    hidden_init: Callable[[jnp.ndarray, Any], jnp.ndarray] = jax.nn.initializers.lecun_uniform()\n",
    "    mean_init: Callable[[jnp.ndarray, Any], jnp.ndarray] = jax.nn.initializers.lecun_uniform()\n",
    "    \n",
    "    def setup(self):\n",
    "        self.hidden_layers = [nn.Dense(features, kernel_init=self.hidden_init, bias_init=self.bias_init) for features in self.hidden_layers_size]\n",
    "        self.mean = nn.Dense(self.action_size, kernel_init=self.mean_init, bias_init=self.bias_init)\n",
    "        self.log_std = self.param(\"log_std\", lambda _, shape: jnp.log(0.5)*jnp.ones(shape), (self.action_size,))\n",
    "        \n",
    "    def distribution_params(self, obs: jnp.ndarray):\n",
    "        hidden = obs\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            hidden = self.activation(hidden_layer(hidden))\n",
    "            \n",
    "        mean = self.mean(hidden)\n",
    "        log_std = self.log_std\n",
    "        std = jnp.exp(log_std)\n",
    "        \n",
    "        return mean, log_std, std\n",
    "    \n",
    "    def logp(self, obs: jnp.ndarray, action: jnp.ndarray):\n",
    "        mean, _, std = self.distribution_params(obs)\n",
    "        logp = jax.scipy.stats.norm.logpdf(action, mean, std)\n",
    "        return logp.sum(axis=-1)\n",
    "    \n",
    "    def __call__(self, random_key: Any, obs: jnp.ndarray):\n",
    "        mean, _, std = self.distribution_params(obs)\n",
    "        \n",
    "        # Sample action\n",
    "        rnd = jax.random.normal(random_key, shape = (self.action_size,))\n",
    "        action = jax.lax.stop_gradient(mean + rnd * std)\n",
    "        \n",
    "        logp = jnp.sum(jax.scipy.stats.norm.logpdf(action, mean, std), axis=-1) \n",
    "                \n",
    "        return action, logp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/my_env/lib/python3.10/site-packages/jax/_src/api_util.py:56\u001b[0m, in \u001b[0;36m_ensure_index_tuple\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     clip_param: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m      7\u001b[0m     grad_steps: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMCPG\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, policy, env):\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config \u001b[38;5;241m=\u001b[39m config\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mMCPG\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     tx \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39madam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TrainState\u001b[38;5;241m.\u001b[39mcreate(apply_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mapply, params\u001b[38;5;241m=\u001b[39mparams, tx\u001b[38;5;241m=\u001b[39mtx)\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;129;43m@partial\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_argnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mself\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 25\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mlogp_fn\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@partial\u001b[39m(jax\u001b[38;5;241m.\u001b[39mjit, static_argnums\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m'\u001b[39m,))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, random_key, train_state, env_state):\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/my_env/lib/python3.10/site-packages/jax/_src/api.py:301\u001b[0m, in \u001b[0;36mjit\u001b[0;34m(fun, in_shardings, out_shardings, static_argnums, static_argnames, donate_argnums, donate_argnames, keep_unused, device, backend, inline, abstracted_axes)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjit\u001b[39m(\n\u001b[1;32m    140\u001b[0m   fun: Callable,\n\u001b[1;32m    141\u001b[0m   in_shardings\u001b[38;5;241m=\u001b[39msharding_impls\u001b[38;5;241m.\u001b[39mUNSPECIFIED,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m   abstracted_axes: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m stages\u001b[38;5;241m.\u001b[39mWrapped:\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets up ``fun`` for just-in-time compilation with XLA.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    Array([   0,    1,  256, 6561], dtype=int32)\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m   (in_shardings, out_shardings, donate_argnums, donate_argnames, static_argnums,\n\u001b[0;32m--> 301\u001b[0m    static_argnames) \u001b[38;5;241m=\u001b[39m \u001b[43mpjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_infer_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonate_argnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonate_argnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_argnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_argnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabstracted_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer_params\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;66;03m# TODO(yashkatariya): Remove this when it's added on jit.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     in_layouts \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_in_layouts\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/my_env/lib/python3.10/site-packages/jax/_src/pjit.py:312\u001b[0m, in \u001b[0;36mpre_infer_params\u001b[0;34m(fun, in_shardings, out_shardings, donate_argnums, donate_argnames, static_argnums, static_argnames, device, backend, abstracted_axes)\u001b[0m\n\u001b[1;32m    309\u001b[0m in_shardings, _, _ \u001b[38;5;241m=\u001b[39m prepare_axis_resources(in_shardings, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_shardings\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    310\u001b[0m out_shardings, _, _ \u001b[38;5;241m=\u001b[39m prepare_axis_resources(out_shardings, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_shardings\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 312\u001b[0m donate_argnums, donate_argnames, static_argnums, static_argnames \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_argnums\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonate_argnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonate_argnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_argnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_argnames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (in_shardings, out_shardings, donate_argnums, donate_argnames,\n\u001b[1;32m    316\u001b[0m         static_argnums, static_argnames)\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/my_env/lib/python3.10/site-packages/jax/_src/api_util.py:532\u001b[0m, in \u001b[0;36mresolve_argnums\u001b[0;34m(fun, donate_argnums, donate_argnames, static_argnums, static_argnames)\u001b[0m\n\u001b[1;32m    527\u001b[0m   donate_argnames \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m   \u001b[38;5;66;03m# Infer argnums and argnames according to docstring\u001b[39;00m\n\u001b[1;32m    530\u001b[0m   \u001b[38;5;66;03m# If nums is None and names is not None, then nums are inferred from the\u001b[39;00m\n\u001b[1;32m    531\u001b[0m   \u001b[38;5;66;03m# names and vice-versa.\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   static_argnums, static_argnames \u001b[38;5;241m=\u001b[39m \u001b[43minfer_argnums_and_argnames\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m      \u001b[49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_argnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_argnames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m   donate_argnums, donate_argnames \u001b[38;5;241m=\u001b[39m infer_argnums_and_argnames(\n\u001b[1;32m    535\u001b[0m       sig, donate_argnums, donate_argnames)\n\u001b[1;32m    537\u001b[0m   \u001b[38;5;66;03m# Validation\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/my_env/lib/python3.10/site-packages/jax/_src/api_util.py:499\u001b[0m, in \u001b[0;36minfer_argnums_and_argnames\u001b[0;34m(sig, argnums, argnames)\u001b[0m\n\u001b[1;32m    494\u001b[0m   argnums \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    495\u001b[0m       i \u001b[38;5;28;01mfor\u001b[39;00m i, (k, param) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(parameters\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    496\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m _POSITIONAL_OR_KEYWORD \u001b[38;5;129;01mand\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m argnames\n\u001b[1;32m    497\u001b[0m   )\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m   argnums \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_index_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43margnums\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m   argnames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    501\u001b[0m       k \u001b[38;5;28;01mfor\u001b[39;00m i, (k, param) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(parameters\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    502\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m _POSITIONAL_OR_KEYWORD \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnums\n\u001b[1;32m    503\u001b[0m   )\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m argnums, argnames\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/my_env/lib/python3.10/site-packages/jax/_src/api_util.py:58\u001b[0m, in \u001b[0;36m_ensure_index_tuple\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (operator\u001b[38;5;241m.\u001b[39mindex(x),)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    no_agents: int = 2\n",
    "    batch_size: int = 2048\n",
    "    mini_batch_size: int = 64\n",
    "    no_epochs: int = 10\n",
    "    learning_rate: float = 3e-4\n",
    "    discount_rate: float = 0.99\n",
    "    clip_param: float = 0.2\n",
    "    grad_steps: int = 10\n",
    "    \n",
    "class MCPG:\n",
    "    \n",
    "    def __init__(self, config, policy, env):\n",
    "        self._config = config\n",
    "        self._policy = policy\n",
    "        self._env = env\n",
    "        \n",
    "    def init(self, random_key):\n",
    "        random_key_1, random_key_2 = jax.random.split(random_key)\n",
    "        fake_obs = jnp.zeros(shape=(self._env.observation_size,))\n",
    "        params = self._policy.init(random_key_1, random_key_2, fake_obs)\n",
    "        tx = optax.adam(learning_rate=self._config.learning_rate)\n",
    "        \n",
    "        return TrainState.create(apply_fn=self._policy.apply, params=params, tx=tx)\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=('self',))\n",
    "    def logp_fn(self, params, obs, action):\n",
    "        return self._policy.apply(params, obs, action, method=self._policy.logp)\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=('self',))\n",
    "    def sample_step(self, random_key, train_state, env_state):\n",
    "        \"\"\"Samples one step in the environment and returns the next state, action and \n",
    "        log-prob of the action.\n",
    "        \"\"\"\n",
    "        \n",
    "        action, action_logp = train_state.apply_fn(train_state.params, random_key, env_state.obs)\n",
    "        \n",
    "        next_env_state = self._env.step(env_state, action)\n",
    "        \n",
    "        return next_env_state, action, action_logp\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=('self',))\n",
    "    def sample_trajectory(self, random_key, train_state):\n",
    "        \"\"\"Samples a full trajectory using the environment and policy.\"\"\"\n",
    "        random_keys = jax.random.split(random_key, self._env.episode_length+1)\n",
    "        env_state_init = self._env.reset(random_keys[-1])\n",
    "        \n",
    "        def _scan_sample_step(carry, x):\n",
    "            (train_state, env_state,) = carry\n",
    "            (random_key, ) = x\n",
    "            \n",
    "            next_env_state, action, action_logp = self.sample_step(random_key, train_state, env_state)\n",
    "            return (train_state, next_env_state), (env_state.obs, action, action_logp, next_env_state.reward, env_state.done, env_state.info[\"state_descriptor\"])\n",
    "        \n",
    "        _, (obs, action, action_logp, reward, done, state_desc) = jax.lax.scan(\n",
    "            _scan_sample_step, \n",
    "            (train_state, env_state_init), \n",
    "            (random_keys[:self._env.episode_length],),\n",
    "            length=self._env.episode_length,\n",
    "            )\n",
    "        \n",
    "        mask = 1. - jnp.clip(jnp.cumsum(done), a_min=0., a_max=1.)\n",
    "        \n",
    "        return obs, action, action_logp, reward, state_desc, mask\n",
    "    \n",
    "    \n",
    "    @partial(jax.jit, static_argnums=('self',))\n",
    "    def get_return(self, reward):\n",
    "        \"\"\" Computes the discounted return for each step in the trajectory.\n",
    "        \"\"\"\n",
    "        \n",
    "        def _body(carry, x):\n",
    "            (next_return,) = carry\n",
    "            (reward,) = x\n",
    "            \n",
    "            current_return = reward + self._config.discount_rate * next_return\n",
    "            return (current_return,), (current_return,)\n",
    "        \n",
    "        _, (return_,) = jax.lax.scan(\n",
    "            _body,\n",
    "            (jnp.array(0.),),\n",
    "            (reward,),\n",
    "            length=self._env.episode_length,\n",
    "            reverse=True,\n",
    "            )\n",
    "            \n",
    "        return return_\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=('self',))\n",
    "    def standardize(self, return_):\n",
    "        return jax.nn.standardize(return_, axis=0, variance=1, epsilon=EPS)\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=('self',))\n",
    "    def get_return_standardize(self, reward, mask):\n",
    "        \"\"\"Standardizes the return values for stability in training\n",
    "        \"\"\"\n",
    "        return_ = jax.vmap(self.get_return)(reward * mask)\n",
    "        return self.standardize(return_)\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=('self',))\n",
    "    def loss_rein(self, params, obs, action, mask, return_standardized):\n",
    "        \"\"\" REINFORCE loss function.\n",
    "        \"\"\"\n",
    "        logp_ = self.logp_fn(params, jax.lax.stop_gradient(obs), jax.lax.stop_gradient(action))\n",
    "        return -jnp.mean(jnp.multiply(logp_ * mask, jax.lax.stop_gradient(return_standardized)))\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=('self',))\n",
    "    def loss_ppo(self, params, obs, action, logp, mask, return_standardized):\n",
    "        \"\"\" PPO loss function.\n",
    "        \"\"\"\n",
    "        \n",
    "        logp_ = self.logp_fn(params, jax.lax.stop_gradient(obs), jax.lax.stop_gradient(action))\n",
    "        ratio = jnp.exp(logp_ - jax.lax.stop_gradient(logp))\n",
    "        \n",
    "        pg_loss_1 = jnp.multiply(ratio * mask, jax.lax.stop_gradient(return_standardized))\n",
    "        pg_loss_2 = jax.lax.stop_gradient(return_standardized) * jax.lax.clamp(1. - self._config.clip_param, ratio, 1. + self._config.clip_param) * mask\n",
    "        return -jnp.mean(jnp.minimum(pg_loss_1, pg_loss_2))\n",
    "    \n",
    "\n",
    "    @partial(jax.jit, static_argnums=('self',))\n",
    "    def flatten_trajectory(self, obs, action, logp, mask, return_standardized):\n",
    "        # Calculate the total number of elements in the combined first two dimensions\n",
    "        total_elements = obs.shape[0] * obs.shape[1]\n",
    "        \n",
    "        # Flatten the first two dimensions\n",
    "        obs = jnp.reshape(obs, (total_elements, obs.shape[2:]))\n",
    "        action = jnp.reshape(action, (total_elements, action.shape[2:]))\n",
    "        logp = jnp.reshape(logp, (total_elements,))\n",
    "        mask = jnp.reshape(mask, (total_elements,))\n",
    "        return_standardized = jnp.reshape(return_standardized, (total_elements,))\n",
    "        \n",
    "        return obs, action, logp, mask, return_standardized\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=('self',))\n",
    "    def train_step(self, random_key, train_state):\n",
    "        # Sample trajectories\n",
    "        random_keys = jax.random.split(random_key, self._config.no_agents+1)\n",
    "        start_time = time.time()\n",
    "        obs, action, logp, reward, _, mask = jax.vmap(self.sample_trajectory, in_axes=(0, None))(random_keys[:self._config.no_agents], train_state)\n",
    "        time_elapsed = time.time() - start_time\n",
    "        \n",
    "        # Compute standaerdized return\n",
    "        return_standardized = self.get_return_standardize(reward, mask)\n",
    "        \n",
    "        obs_, action_, logp_, mask_, return_standardized_ = self.flatten_trajectory(obs, action, logp, mask, return_standardized)\n",
    "        b_inds = random.permutation(random_keys[-1], self._config.batch_size)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
