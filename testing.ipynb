{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  1 01:31:19 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080        Off | 00000000:2D:00.0 Off |                  N/A |\n",
      "|  0%   49C    P3              56W / 320W |     86MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      5728      G   /usr/lib/xorg/Xorg                           78MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['MPLCONFIGDIR'] = '/tmp/matplotlib'\n",
    "os.environ['WANDB_CACHE_DIR'] = '/tmp/wandb_cache'\n",
    "os.environ['JAX_LOG_COMPILATION'] = '1'\n",
    "\n",
    "import logging\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from math import floor\n",
    "from typing import Any, Dict, Tuple, List, Callable\n",
    "import pickle\n",
    "from flax import serialization\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "import hydra\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from hydra.core.config_store import ConfigStore\n",
    "from qdax.core.map_elites import MAPElites\n",
    "from qdax.types import RNGKey, Genotype\n",
    "from qdax.utils.sampling import sampling \n",
    "from qdax.core.containers.mapelites_repertoire import compute_cvt_centroids, MapElitesRepertoire\n",
    "from qdax.core.neuroevolution.networks.networks import MLP, MLPRein\n",
    "from qdax.core.emitters.rein_var import REINConfig, REINEmitter\n",
    "#from qdax.core.emitters.rein_emitter_advanced import REINaiveConfig, REINaiveEmitter\n",
    "from qdax.core.neuroevolution.buffers.buffer import QDTransition\n",
    "from qdax.environments import behavior_descriptor_extractor\n",
    "from qdax.tasks.brax_envs import reset_based_scoring_function_brax_envs as scoring_function\n",
    "from utils import Config, get_env\n",
    "from qdax.core.emitters.mutation_operators import isoline_variation\n",
    "import wandb\n",
    "from qdax.utils.metrics import CSVLogger, default_qd_metrics\n",
    "from qdax.utils.plotting import plot_map_elites_results, plot_2d_map_elites_repertoire\n",
    "import matplotlib.pyplot as plt\n",
    "from set_up_brax import get_reward_offset_brax\n",
    "from qdax import environments_v1, environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(env_name):\n",
    "    if env_name == \"hopper_uni\":\n",
    "        episode_length = 1000\n",
    "        \n",
    "        env = environments_v1.create(env_name, episode_length=episode_length)\n",
    "    elif env_name == \"halfcheetah_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length)\n",
    "        \n",
    "    elif env_name == \"walker2d_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length)\t\n",
    "    elif env_name == \"ant_uni\":\n",
    "        episode_length = 10\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length, use_contact_forces=False, exclude_current_positions_from_observation=True)\n",
    "    elif env_name == \"humanoid_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length, exclude_current_positions_from_observation=True)\t\n",
    "    '''\n",
    "    elif env_name == \"ant_omni\":\n",
    "        episode_length = 250\n",
    "        max_bd = 30.\n",
    "\n",
    "        env = environments.create(env_name, episode_length=episode_length, use_contact_forces=False, exclude_current_positions_from_observation=False)\t\n",
    "    elif env_name == \"humanoid_uni\":\n",
    "        episode_length = 1000\n",
    "        max_bd = 1.\n",
    "\n",
    "        env = environments.create(env_name, episode_length=episode_length)\t\n",
    "    else:\n",
    "        ValueError(f\"Environment {env_name} not supported.\")\n",
    "    '''\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration from this experiment script\n",
    "    \"\"\"\n",
    "    # Env config\n",
    "    #alg_name: str\n",
    "    seed: int\n",
    "    env_name: str\n",
    "    episode_length: int\n",
    "    policy_hidden_layer_sizes: Tuple[int, ...]   \n",
    "    # ME config\n",
    "    num_evaluations: int\n",
    "    num_iterations: int\n",
    "    batch_size: int\n",
    "    num_samples: int\n",
    "    fixed_init_state: bool\n",
    "    discard_dead: bool\n",
    "    # Emitter config\n",
    "    iso_sigma: float\n",
    "    line_sigma: float\n",
    "    #crossover_percentage: float\n",
    "    # Grid config \n",
    "    grid_shape: Tuple[int, ...]\n",
    "    num_init_cvt_samples: int\n",
    "    num_centroids: int\n",
    "    # Log config\n",
    "    log_period: int\n",
    "    store_repertoire: bool\n",
    "    store_repertoire_log_period: int\n",
    "    \n",
    "    # REINFORCE Parameters\n",
    "    proportion_mutation_ga : float\n",
    "    rollout_number: int\n",
    "    num_rein_training_steps: int\n",
    "    adam_optimizer: bool\n",
    "    learning_rate: float\n",
    "    discount_rate: float\n",
    "    temperature: int\n",
    "    buffer_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    seed=0,\n",
    "    env_name='ant_uni',\n",
    "    episode_length=10,\n",
    "    policy_hidden_layer_sizes=[128, 128],\n",
    "    num_evaluations=0,\n",
    "    num_iterations=200,\n",
    "    num_samples=32,\n",
    "    batch_size=10,\n",
    "    fixed_init_state=False,\n",
    "    discard_dead=False,\n",
    "    grid_shape=[50, 50],\n",
    "    num_init_cvt_samples=50000,\n",
    "    num_centroids=1296,\n",
    "    log_period=400,\n",
    "    store_repertoire=True,\n",
    "    store_repertoire_log_period=800,\n",
    "    iso_sigma=0.005,\n",
    "    line_sigma=0.05,\n",
    "    proportion_mutation_ga=0.5,\n",
    "    rollout_number=1, # Num of episodes used for gradient estimate\n",
    "    num_rein_training_steps=1, # Num gradient steps per generation\n",
    "    buffer_size=200, # Size of the replay buffer\n",
    "    adam_optimizer=True,\n",
    "    learning_rate=1e-3,\n",
    "    discount_rate=0.99,\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 128]\n",
      "Number of parameters in policy_network:  21264\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/qdax/core/map_elites.py:80: UserWarning: This type of repertoire does not store the extra scores computed by the scoring function\n",
      "  repertoire = MapElitesRepertoire.init(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(num_loops):\\n    print(f\"Loop {i+1}/{num_loops}\")\\n    start_time = time.time()\\n    \\n    (repertoire, emitter_state, random_key,), current_metrics = jax.lax.scan(\\n        map_elites_scan_update,\\n        (repertoire, emitter_state, random_key),\\n        (),\\n        length=log_period,\\n    )\\n    timelapse = time.time() - start_time\\n    \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init a random key\n",
    "random_key = jax.random.PRNGKey(config.seed)\n",
    "\n",
    "# Init environment\n",
    "env = get_env(\"ant_uni\")\n",
    "reset_fn = jax.jit(env.reset)\n",
    "\n",
    "# Compute the centroids\n",
    "centroids, random_key = compute_cvt_centroids(\n",
    "    num_descriptors=env.behavior_descriptor_length,\n",
    "    num_init_cvt_samples=config.num_init_cvt_samples,\n",
    "    num_centroids=config.num_centroids,\n",
    "    minval=0,\n",
    "    maxval=1,\n",
    "    random_key=random_key,\n",
    ")\n",
    "# Init policy network\n",
    "policy_layer_sizes = config.policy_hidden_layer_sizes #+ (env.action_size,)\n",
    "print(policy_layer_sizes)\n",
    "\n",
    "'''\n",
    "policy_network = MLPRein(\n",
    "    action_size=env.action_size,\n",
    "    layer_sizes=policy_layer_sizes,\n",
    "    kernel_init=jax.nn.initializers.orthogonal(scale=jnp.sqrt(2)),\n",
    "    kernel_init_final=jax.nn.initializers.orthogonal(scale=0.01),\n",
    ")\n",
    "'''\n",
    "policy_network = MLPRein(\n",
    "    action_size=env.action_size,\n",
    "    layer_sizes=policy_layer_sizes,\n",
    "    kernel_init=jax.nn.initializers.lecun_uniform(),\n",
    "    kernel_init_final=jax.nn.initializers.lecun_uniform(),\n",
    ")\n",
    "\n",
    "\n",
    "# Init population of controllers\n",
    "\n",
    "# maybe consider adding two random keys for each policy\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "keys = jax.random.split(subkey, num=config.batch_size)\n",
    "#split_keys = jax.vmap(lambda k: jax.random.split(k, 2))(keys)\n",
    "#keys1, keys2 = split_keys[:, 0], split_keys[:, 1]\n",
    "fake_batch_obs = jnp.zeros(shape=(config.batch_size, env.observation_size))\n",
    "init_params = jax.vmap(policy_network.init)(keys, fake_batch_obs)\n",
    "\n",
    "param_count = sum(x[0].size for x in jax.tree_util.tree_leaves(init_params))\n",
    "print(\"Number of parameters in policy_network: \", param_count)\n",
    "\n",
    "# Define the fonction to play a step with the policy in the environment\n",
    "def play_step_fn(env_state, policy_params, random_key):\n",
    "    #random_key, subkey = jax.random.split(random_key)\n",
    "    actions = policy_network.apply(policy_params, env_state.obs)\n",
    "    state_desc = env_state.info[\"state_descriptor\"]\n",
    "    next_state = env.step(env_state, actions)\n",
    "\n",
    "    transition = QDTransition(\n",
    "        obs=env_state.obs,\n",
    "        next_obs=next_state.obs,\n",
    "        rewards=next_state.reward,\n",
    "        dones=next_state.done,\n",
    "        truncations=next_state.info[\"truncation\"],\n",
    "        actions=actions,\n",
    "        state_desc=state_desc,\n",
    "        next_state_desc=next_state.info[\"state_descriptor\"],\n",
    "        #desc=jnp.zeros(env.behavior_descriptor_length,) * jnp.nan,\n",
    "        #desc_prime=jnp.zeros(env.behavior_descriptor_length,) * jnp.nan,\n",
    "    )\n",
    "\n",
    "    return next_state, policy_params, random_key, transition\n",
    "\n",
    "# Prepare the scoring function\n",
    "bd_extraction_fn = behavior_descriptor_extractor['ant_uni']\n",
    "scoring_fn = partial(\n",
    "    scoring_function,\n",
    "    episode_length=env.episode_length,\n",
    "    play_reset_fn=reset_fn,\n",
    "    play_step_fn=play_step_fn,\n",
    "    behavior_descriptor_extractor=bd_extraction_fn,\n",
    ")\n",
    "#reward_offset = get_reward_offset_brax(env, config.env_name)\n",
    "#print(f\"Reward offset: {reward_offset}\")\n",
    "\n",
    "me_scoring_fn = partial(\n",
    "sampling,\n",
    "scoring_fn=scoring_fn,\n",
    "num_samples=config.num_samples,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "reward_offset = 0\n",
    "\n",
    "\n",
    "\n",
    "# Get minimum reward value to make sure qd_score are positive\n",
    "\n",
    "\n",
    "# Define a metrics function\n",
    "metrics_function = partial(\n",
    "    default_qd_metrics,\n",
    "    qd_offset=reward_offset * env.episode_length,\n",
    ")\n",
    "\n",
    "# Define the PG-emitter config\n",
    "\n",
    "rein_emitter_config = REINConfig(\n",
    "    proportion_mutation_ga=config.proportion_mutation_ga,\n",
    "    batch_size=config.batch_size,\n",
    "    num_rein_training_steps=config.num_rein_training_steps,\n",
    "    buffer_size=config.buffer_size,\n",
    "    rollout_number=config.rollout_number,\n",
    "    discount_rate=config.discount_rate,\n",
    "    adam_optimizer=config.adam_optimizer,\n",
    "    learning_rate=config.learning_rate,\n",
    ")\n",
    "\n",
    "\n",
    "variation_fn = partial(\n",
    "    isoline_variation, iso_sigma=config.iso_sigma, line_sigma=config.line_sigma\n",
    ")\n",
    "\n",
    "rein_emitter = REINEmitter(\n",
    "    config=rein_emitter_config,\n",
    "    policy_network=policy_network,\n",
    "    env=env,\n",
    "    variation_fn=variation_fn,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate MAP Elites\n",
    "map_elites = MAPElites(\n",
    "    scoring_function=scoring_fn,\n",
    "    emitter=rein_emitter,\n",
    "    metrics_function=metrics_function,\n",
    ")\n",
    "\n",
    "# compute initial repertoire\n",
    "repertoire, emitter_state, random_key = map_elites.init(init_params, centroids, random_key)\n",
    "\n",
    "log_period = 1\n",
    "num_loops = int(config.num_iterations / log_period)\n",
    "\n",
    "\n",
    "# Main loop\n",
    "map_elites_scan_update = map_elites.scan_update\n",
    "'''\n",
    "for i in range(num_loops):\n",
    "    print(f\"Loop {i+1}/{num_loops}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    (repertoire, emitter_state, random_key,), current_metrics = jax.lax.scan(\n",
    "        map_elites_scan_update,\n",
    "        (repertoire, emitter_state, random_key),\n",
    "        (),\n",
    "        length=log_period,\n",
    "    )\n",
    "    timelapse = time.time() - start_time\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dones : [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Flattened transitions pre: [[[ 0.5473534   1.          0.         ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.53608376  0.99988157  0.00364783 ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.5102447   0.9995933   0.00332651 ...  0.          1.\n",
      "    1.        ]\n",
      "  ...\n",
      "  [ 0.52190715  0.9976168  -0.00360796 ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.54783225  0.99806434 -0.00888216 ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.59710866  0.9972295  -0.00430547 ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.5230979   1.          0.         ...  0.          0.\n",
      "    1.        ]\n",
      "  [ 0.5165462   0.9990979  -0.01194586 ...  0.          1.\n",
      "    1.        ]\n",
      "  [ 0.5282194   0.99505246 -0.01466167 ...  0.          1.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.62694985  0.9981066   0.04968536 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.6574385   0.9990636   0.02535998 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.6559932   0.9989094   0.00187646 ...  0.          0.\n",
      "    1.        ]]\n",
      "\n",
      " [[ 0.5461359   1.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.53484696  0.9999555  -0.00935901 ...  0.          1.\n",
      "    1.        ]\n",
      "  [ 0.49996072  0.99902433 -0.03880405 ...  0.          1.\n",
      "    1.        ]\n",
      "  ...\n",
      "  [ 0.5049912   0.99549305  0.03747843 ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.5598996   0.99474716  0.0290777  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5888126   0.9948765  -0.00699779 ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.5311169   1.          0.         ...  1.          0.\n",
      "    0.        ]\n",
      "  [ 0.5255388   0.99977577  0.01485095 ...  1.          0.\n",
      "    0.        ]\n",
      "  [ 0.5120797   0.9975031   0.05386551 ...  0.          0.\n",
      "    1.        ]\n",
      "  ...\n",
      "  [ 0.5010717   0.99463904  0.09219375 ...  1.          1.\n",
      "    1.        ]\n",
      "  [ 0.539493    0.9897218   0.09740392 ...  1.          1.\n",
      "    0.        ]\n",
      "  [ 0.58886945  0.9929636   0.09830653 ...  1.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.54204094  1.          0.         ...  1.          0.\n",
      "    1.        ]\n",
      "  [ 0.5325074   0.99997026 -0.00761665 ...  1.          1.\n",
      "    1.        ]\n",
      "  [ 0.5186644   0.999035   -0.038658   ...  0.          1.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.5188064   0.99622935  0.04625463 ...  1.          1.\n",
      "    0.        ]\n",
      "  [ 0.59855354  0.99318343  0.06608324 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.6533342   0.99415255  0.0655527  ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.53063506  1.          0.         ...  0.          0.\n",
      "    1.        ]\n",
      "  [ 0.5210905   0.99985415 -0.0080062  ...  1.          1.\n",
      "    1.        ]\n",
      "  [ 0.49989215  0.99737746 -0.04140856 ...  1.          1.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.4739606   0.99645257  0.07290918 ...  0.          1.\n",
      "    1.        ]\n",
      "  [ 0.5121775   0.994782    0.08261126 ...  1.          1.\n",
      "    1.        ]\n",
      "  [ 0.5303157   0.99330294  0.08624325 ...  0.          0.\n",
      "    0.        ]]]\n",
      "Flattened transitions post: [[[ 0.5473534   1.          0.         ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.5230979   1.          0.         ...  0.          0.\n",
      "    1.        ]\n",
      "  [ 0.5461359   1.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.5311169   1.          0.         ...  1.          0.\n",
      "    0.        ]\n",
      "  [ 0.54204094  1.          0.         ...  1.          0.\n",
      "    1.        ]\n",
      "  [ 0.53063506  1.          0.         ...  0.          0.\n",
      "    1.        ]]\n",
      "\n",
      " [[ 0.53608376  0.99988157  0.00364783 ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.5165462   0.9990979  -0.01194586 ...  0.          1.\n",
      "    1.        ]\n",
      "  [ 0.53484696  0.9999555  -0.00935901 ...  0.          1.\n",
      "    1.        ]\n",
      "  ...\n",
      "  [ 0.5255388   0.99977577  0.01485095 ...  1.          0.\n",
      "    0.        ]\n",
      "  [ 0.5325074   0.99997026 -0.00761665 ...  1.          1.\n",
      "    1.        ]\n",
      "  [ 0.5210905   0.99985415 -0.0080062  ...  1.          1.\n",
      "    1.        ]]\n",
      "\n",
      " [[ 0.5102447   0.9995933   0.00332651 ...  0.          1.\n",
      "    1.        ]\n",
      "  [ 0.5282194   0.99505246 -0.01466167 ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.49996072  0.99902433 -0.03880405 ...  0.          1.\n",
      "    1.        ]\n",
      "  ...\n",
      "  [ 0.5120797   0.9975031   0.05386551 ...  0.          0.\n",
      "    1.        ]\n",
      "  [ 0.5186644   0.999035   -0.038658   ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.49989215  0.99737746 -0.04140856 ...  1.          1.\n",
      "    0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.52190715  0.9976168  -0.00360796 ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.62694985  0.9981066   0.04968536 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5049912   0.99549305  0.03747843 ...  0.          1.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.5010717   0.99463904  0.09219375 ...  1.          1.\n",
      "    1.        ]\n",
      "  [ 0.5188064   0.99622935  0.04625463 ...  1.          1.\n",
      "    0.        ]\n",
      "  [ 0.4739606   0.99645257  0.07290918 ...  0.          1.\n",
      "    1.        ]]\n",
      "\n",
      " [[ 0.54783225  0.99806434 -0.00888216 ...  0.          1.\n",
      "    0.        ]\n",
      "  [ 0.6574385   0.9990636   0.02535998 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5598996   0.99474716  0.0290777  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.539493    0.9897218   0.09740392 ...  1.          1.\n",
      "    0.        ]\n",
      "  [ 0.59855354  0.99318343  0.06608324 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5121775   0.994782    0.08261126 ...  1.          1.\n",
      "    1.        ]]\n",
      "\n",
      " [[ 0.59710866  0.9972295  -0.00430547 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.6559932   0.9989094   0.00187646 ...  0.          0.\n",
      "    1.        ]\n",
      "  [ 0.5888126   0.9948765  -0.00699779 ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.58886945  0.9929636   0.09830653 ...  1.          0.\n",
      "    0.        ]\n",
      "  [ 0.6533342   0.99415255  0.0655527  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5303157   0.99330294  0.08624325 ...  0.          0.\n",
      "    0.        ]]]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "repertoire, emitter_state, metrics, random_key = map_elites.update(repertoire, emitter_state, random_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = emitter_state.emitter_states[0].trajectory_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ArrayImpl' object has no attribute 'masks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasks\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ArrayImpl' object has no attribute 'masks'"
     ]
    }
   ],
   "source": [
    "x.data.masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode length: 10\n",
      "\n",
      "Environment batch size: 10\n",
      "\n",
      "Number of trajectories: 20\n",
      "\n",
      "Current position: 0\n",
      "\n",
      "Current size: 200\n",
      "\n",
      "Trajectory positions: [4 4 4 4 4 4 4 4 4 4]\n",
      "\n",
      "Timestep positions: [0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Episodic data: [[  0.  10.  20.  30.  40.  50.  60.  70.  80.  90.]\n",
      " [  1.  11.  21.  31.  41.  51.  61.  71.  81.  91.]\n",
      " [  2.  12.  22.  32.  42.  52.  62.  72.  82.  92.]\n",
      " [  3.  13.  23.  33.  43.  53.  63.  73.  83.  93.]\n",
      " [  4.  14.  24.  34.  44.  54.  64.  74.  84.  94.]\n",
      " [  5.  15.  25.  35.  45.  55.  65.  75.  85.  95.]\n",
      " [  6.  16.  26.  36.  46.  56.  66.  76.  86.  96.]\n",
      " [  7.  17.  27.  37.  47.  57.  67.  77.  87.  97.]\n",
      " [  8.  18.  28.  38.  48.  58.  68.  78.  88.  98.]\n",
      " [  9.  19.  29.  39.  49.  59.  69.  79.  89.  99.]\n",
      " [100. 110. 120. 130. 140. 150. 160. 170. 180. 190.]\n",
      " [101. 111. 121. 131. 141. 151. 161. 171. 181. 191.]\n",
      " [102. 112. 122. 132. 142. 152. 162. 172. 182. 192.]\n",
      " [103. 113. 123. 133. 143. 153. 163. 173. 183. 193.]\n",
      " [104. 114. 124. 134. 144. 154. 164. 174. 184. 194.]\n",
      " [105. 115. 125. 135. 145. 155. 165. 175. 185. 195.]\n",
      " [106. 116. 126. 136. 146. 156. 166. 176. 186. 196.]\n",
      " [107. 117. 127. 137. 147. 157. 167. 177. 187. 197.]\n",
      " [108. 118. 128. 138. 148. 158. 168. 178. 188. 198.]\n",
      " [109. 119. 129. 139. 149. 159. 169. 179. 189. 199.]]\n",
      "\n",
      "Current episodic data size: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Episode length: {x.episode_length}\\n\")\n",
    "print(f\"Environment batch size: {x.env_batch_size}\\n\")\n",
    "print(f\"Number of trajectories: {x.num_trajectories}\\n\")\n",
    "\n",
    "print(f\"Current position: {x.current_position}\\n\")\n",
    "print(f\"Current size: {x.current_size}\\n\")\n",
    "print(f\"Trajectory positions: {x.trajectory_positions}\\n\")\n",
    "print(f\"Timestep positions: {x.timestep_positions}\\n\")\n",
    "print(f\"Episodic data: {x.episodic_data}\\n\")\n",
    "print(f\"Current episodic data size: {x.current_episodic_data_size}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(10, dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.current_episodic_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transitions size: (array(10, dtype=int32), array(10, dtype=int32), array(28, dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "repertoire, emitter_state, metrics, random_key = map_elites.update(repertoire, emitter_state, random_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = emitter_state.emitter_states[0].trajectory_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode length: 10\n",
      "\n",
      "Environment batch size: 5\n",
      "\n",
      "Number of trajectories: 20\n",
      "\n",
      "Current position: 0\n",
      "\n",
      "Current size: 200\n",
      "\n",
      "Trajectory positions: [ 0  0  0  0 20]\n",
      "\n",
      "Timestep positions: [40 40 40 40  0]\n",
      "\n",
      "Episodic data: [[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [164. 169.  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [174. 179.  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [184. 189.  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [194. 199.  nan  nan  nan  nan  nan  nan  nan  nan]]\n",
      "\n",
      "Current episodic data size: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Episode length: {x.episode_length}\\n\")\n",
    "print(f\"Environment batch size: {x.env_batch_size}\\n\")\n",
    "print(f\"Number of trajectories: {x.num_trajectories}\\n\")\n",
    "\n",
    "print(f\"Current position: {x.current_position}\\n\")\n",
    "print(f\"Current size: {x.current_size}\\n\")\n",
    "print(f\"Trajectory positions: {x.trajectory_positions}\\n\")\n",
    "print(f\"Timestep positions: {x.timestep_positions}\\n\")\n",
    "print(f\"Episodic data: {x.episodic_data}\\n\")\n",
    "print(f\"Current episodic data size: {x.current_episodic_data_size}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transition.dones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
