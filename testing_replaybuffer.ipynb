{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  4 00:21:12 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A30                     Off | 00000000:01:00.0 Off |                   On |\n",
      "| N/A   31C    P0              28W / 165W |   9270MiB / 24576MiB |     N/A      Default |\n",
      "|                                         |                      |              Enabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "\n",
      "+---------------------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                          |\n",
      "+------------------+--------------------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n",
      "|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n",
      "|                  |                                |        ECC|                       |\n",
      "|==================+================================+===========+=======================|\n",
      "|  0    1   0   0  |            9245MiB / 11968MiB  | 28      0 |  2   0    2    0    0 |\n",
      "|                  |               2MiB / 16383MiB  |           |                       |\n",
      "+------------------+--------------------------------+-----------+-----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0    1    0    3202866      C   ...-sample-based-drl/my_env/bin/python     9212MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 23:48:31.535384: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 12549357568\n",
      "CUDA backend failed to initialize: INTERNAL: no supported devices found for platform CUDA (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['MPLCONFIGDIR'] = '/tmp/matplotlib'\n",
    "os.environ['WANDB_CACHE_DIR'] = '/tmp/wandb_cache'\n",
    "os.environ['JAX_LOG_COMPILATION'] = '1'\n",
    "\n",
    "import logging\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from math import floor\n",
    "from typing import Any, Dict, Tuple, List, Callable\n",
    "import pickle\n",
    "from flax import serialization\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "import hydra\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from hydra.core.config_store import ConfigStore\n",
    "from qdax.core.map_elites import MAPElites\n",
    "from qdax.types import RNGKey, Genotype\n",
    "from qdax.utils.sampling import sampling \n",
    "from qdax.core.containers.mapelites_repertoire import compute_cvt_centroids, MapElitesRepertoire\n",
    "from qdax.core.neuroevolution.networks.networks import MLP, MLPRein\n",
    "from qdax.core.emitters.rein_var import REINConfig, REINEmitter\n",
    "#from qdax.core.emitters.rein_emitter_advanced import REINaiveConfig, REINaiveEmitter\n",
    "from qdax.core.neuroevolution.buffers.buffer import QDTransition\n",
    "from qdax.environments import behavior_descriptor_extractor\n",
    "from qdax.tasks.brax_envs import reset_based_scoring_function_brax_envs as scoring_function\n",
    "from utils import Config, get_env\n",
    "from qdax.core.emitters.mutation_operators import isoline_variation\n",
    "import wandb\n",
    "from qdax.utils.metrics import CSVLogger, default_qd_metrics\n",
    "from qdax.utils.plotting import plot_map_elites_results, plot_2d_map_elites_repertoire\n",
    "import matplotlib.pyplot as plt\n",
    "from set_up_brax import get_reward_offset_brax\n",
    "from qdax import environments_v1, environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(env_name):\n",
    "    if env_name == \"hopper_uni\":\n",
    "        episode_length = 1000\n",
    "        \n",
    "        env = environments_v1.create(env_name, episode_length=episode_length)\n",
    "    elif env_name == \"halfcheetah_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length)\n",
    "        \n",
    "    elif env_name == \"walker2d_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length)\t\n",
    "    elif env_name == \"ant_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length, use_contact_forces=False, exclude_current_positions_from_observation=True)\n",
    "    elif env_name == \"humanoid_uni\":\n",
    "        episode_length = 1000\n",
    "\n",
    "        env = environments_v1.create(env_name, episode_length=episode_length, exclude_current_positions_from_observation=True)\t\n",
    "    '''\n",
    "    elif env_name == \"ant_omni\":\n",
    "        episode_length = 250\n",
    "        max_bd = 30.\n",
    "\n",
    "        env = environments.create(env_name, episode_length=episode_length, use_contact_forces=False, exclude_current_positions_from_observation=False)\t\n",
    "    elif env_name == \"humanoid_uni\":\n",
    "        episode_length = 1000\n",
    "        max_bd = 1.\n",
    "\n",
    "        env = environments.create(env_name, episode_length=episode_length)\t\n",
    "    else:\n",
    "        ValueError(f\"Environment {env_name} not supported.\")\n",
    "    '''\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration from this experiment script\n",
    "    \"\"\"\n",
    "    # Env config\n",
    "    #alg_name: str\n",
    "    seed: int\n",
    "    env_name: str\n",
    "    episode_length: int\n",
    "    policy_hidden_layer_sizes: Tuple[int, ...]   \n",
    "    # ME config\n",
    "    num_evaluations: int\n",
    "    num_iterations: int\n",
    "    batch_size: int\n",
    "    num_samples: int\n",
    "    fixed_init_state: bool\n",
    "    discard_dead: bool\n",
    "    # Emitter config\n",
    "    iso_sigma: float\n",
    "    line_sigma: float\n",
    "    #crossover_percentage: float\n",
    "    # Grid config \n",
    "    grid_shape: Tuple[int, ...]\n",
    "    num_init_cvt_samples: int\n",
    "    num_centroids: int\n",
    "    # Log config\n",
    "    log_period: int\n",
    "    store_repertoire: bool\n",
    "    store_repertoire_log_period: int\n",
    "    \n",
    "    # REINFORCE Parameters\n",
    "    proportion_mutation_ga : float\n",
    "    rollout_number: int\n",
    "    num_rein_training_steps: int\n",
    "    adam_optimizer: bool\n",
    "    learning_rate: float\n",
    "    discount_rate: float\n",
    "    temperature: int\n",
    "    buffer_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    seed=0,\n",
    "    env_name='ant_uni',\n",
    "    episode_length=20,\n",
    "    policy_hidden_layer_sizes=[128, 128],\n",
    "    num_evaluations=0,\n",
    "    num_iterations=200,\n",
    "    num_samples=32,\n",
    "    batch_size=10,\n",
    "    fixed_init_state=False,\n",
    "    discard_dead=False,\n",
    "    grid_shape=[50, 50],\n",
    "    num_init_cvt_samples=50000,\n",
    "    num_centroids=1296,\n",
    "    log_period=400,\n",
    "    store_repertoire=True,\n",
    "    store_repertoire_log_period=800,\n",
    "    iso_sigma=0.005,\n",
    "    line_sigma=0.05,\n",
    "    proportion_mutation_ga=0.5,\n",
    "    rollout_number=1, # Num of episodes used for gradient estimate\n",
    "    num_rein_training_steps=1, # Num gradient steps per generation\n",
    "    buffer_size=400, # Size of the replay buffer\n",
    "    adam_optimizer=True,\n",
    "    learning_rate=1e-3,\n",
    "    discount_rate=0.99,\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 128]\n",
      "Number of parameters in policy_network:  21264\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/qdax/core/map_elites.py:82: UserWarning: This type of repertoire does not store the extra scores computed by the scoring function\n",
      "  repertoire = MapElitesRepertoire.init(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "buffer_size must be a multiple of episode_length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 140\u001b[0m\n\u001b[1;32m    133\u001b[0m map_elites \u001b[38;5;241m=\u001b[39m MAPElites(\n\u001b[1;32m    134\u001b[0m     scoring_function\u001b[38;5;241m=\u001b[39mscoring_fn,\n\u001b[1;32m    135\u001b[0m     emitter\u001b[38;5;241m=\u001b[39mrein_emitter,\n\u001b[1;32m    136\u001b[0m     metrics_function\u001b[38;5;241m=\u001b[39mmetrics_function,\n\u001b[1;32m    137\u001b[0m )\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# compute initial repertoire\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m repertoire, emitter_state, random_key \u001b[38;5;241m=\u001b[39m \u001b[43mmap_elites\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m log_period \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    143\u001b[0m num_loops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_iterations \u001b[38;5;241m/\u001b[39m log_period)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/qdax/core/map_elites.py:103\u001b[0m, in \u001b[0;36mMAPElites.init\u001b[0;34m(self, genotypes, centroids, random_key)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# get initial state of the emitter\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03memitter_state, random_key = self._emitter.init(\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    random_key=random_key,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m)\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m emitter_state, random_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_emitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepertoire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepertoire\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenotypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenotypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfitnesses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfitnesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescriptors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescriptors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m emitter_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_emitter\u001b[38;5;241m.\u001b[39mstate_update(\n\u001b[1;32m    113\u001b[0m     emitter_state\u001b[38;5;241m=\u001b[39memitter_state,\n\u001b[1;32m    114\u001b[0m     repertoire\u001b[38;5;241m=\u001b[39mrepertoire,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     extra_scores\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_scores}\u001b[38;5;66;03m#, **extra_info},\u001b[39;00m\n\u001b[1;32m    119\u001b[0m )\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repertoire, emitter_state, random_key\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/qdax/core/emitters/multi_emitter.py:85\u001b[0m, in \u001b[0;36mMultiEmitter.init\u001b[0;34m(self, random_key, repertoire, genotypes, fitnesses, descriptors, extra_scores)\u001b[0m\n\u001b[1;32m     83\u001b[0m emitter_states \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m emitter, subkey_emitter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memitters, subkeys):\n\u001b[0;32m---> 85\u001b[0m     emitter_state, _ \u001b[38;5;241m=\u001b[39m \u001b[43memitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubkey_emitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepertoire\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenotypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfitnesses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescriptors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     emitter_states\u001b[38;5;241m.\u001b[39mappend(emitter_state)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MultiEmitterState(\u001b[38;5;28mtuple\u001b[39m(emitter_states)), random_key\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/qdax/core/emitters/rein_emitter.py:136\u001b[0m, in \u001b[0;36mREINaiveEmitter.init\u001b[0;34m(self, random_key, repertoire, genotypes, fitnesses, descriptors, extra_scores)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Init trajectory buffer\u001b[39;00m\n\u001b[1;32m    130\u001b[0m dummy_transition \u001b[38;5;241m=\u001b[39m QDTransition\u001b[38;5;241m.\u001b[39minit_dummy(\n\u001b[1;32m    131\u001b[0m     observation_dim\u001b[38;5;241m=\u001b[39mobservation_size,\n\u001b[1;32m    132\u001b[0m     action_dim\u001b[38;5;241m=\u001b[39maction_size,\n\u001b[1;32m    133\u001b[0m     descriptor_dim\u001b[38;5;241m=\u001b[39mdescriptor_size,\n\u001b[1;32m    134\u001b[0m )\n\u001b[0;32m--> 136\u001b[0m trajectory_buffer \u001b[38;5;241m=\u001b[39m \u001b[43mTrajectoryBuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_transition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepisode_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepisode_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m random_key, subkey \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(random_key)\n\u001b[1;32m    144\u001b[0m emitter_state \u001b[38;5;241m=\u001b[39m REINaiveEmitterState(\n\u001b[1;32m    145\u001b[0m     trajectory_buffer\u001b[38;5;241m=\u001b[39mtrajectory_buffer,\n\u001b[1;32m    146\u001b[0m     random_key\u001b[38;5;241m=\u001b[39msubkey,\n\u001b[1;32m    147\u001b[0m )\n",
      "File \u001b[0;32m/vol/bitbucket/km2120/QD-DRL/me-with-sample-based-drl/qdax/core/neuroevolution/buffers/trajectory_buffer.py:93\u001b[0m, in \u001b[0;36mTrajectoryBuffer.init\u001b[0;34m(cls, buffer_size, transition, env_batch_size, episode_length)\u001b[0m\n\u001b[1;32m     87\u001b[0m num_trajectories \u001b[38;5;241m=\u001b[39m buffer_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m episode_length\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     90\u001b[0m     num_trajectories \u001b[38;5;241m%\u001b[39m env_batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     91\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_trajectories must be a multiple of env batch size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m---> 93\u001b[0m     buffer_size \u001b[38;5;241m%\u001b[39m episode_length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuffer_size must be a multiple of episode_length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m current_position \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros((), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     98\u001b[0m trajectory_positions \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros(env_batch_size, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: buffer_size must be a multiple of episode_length"
     ]
    }
   ],
   "source": [
    "# Init a random key\n",
    "random_key = jax.random.PRNGKey(config.seed)\n",
    "\n",
    "# Init environment\n",
    "env = get_env(\"ant_uni\")\n",
    "reset_fn = jax.jit(env.reset)\n",
    "\n",
    "# Compute the centroids\n",
    "centroids, random_key = compute_cvt_centroids(\n",
    "    num_descriptors=env.behavior_descriptor_length,\n",
    "    num_init_cvt_samples=config.num_init_cvt_samples,\n",
    "    num_centroids=config.num_centroids,\n",
    "    minval=0,\n",
    "    maxval=1,\n",
    "    random_key=random_key,\n",
    ")\n",
    "# Init policy network\n",
    "policy_layer_sizes = config.policy_hidden_layer_sizes #+ (env.action_size,)\n",
    "print(policy_layer_sizes)\n",
    "\n",
    "'''\n",
    "policy_network = MLPRein(\n",
    "    action_size=env.action_size,\n",
    "    layer_sizes=policy_layer_sizes,\n",
    "    kernel_init=jax.nn.initializers.orthogonal(scale=jnp.sqrt(2)),\n",
    "    kernel_init_final=jax.nn.initializers.orthogonal(scale=0.01),\n",
    ")\n",
    "'''\n",
    "policy_network = MLPRein(\n",
    "    action_size=env.action_size,\n",
    "    layer_sizes=policy_layer_sizes,\n",
    "    kernel_init=jax.nn.initializers.lecun_uniform(),\n",
    "    kernel_init_final=jax.nn.initializers.lecun_uniform(),\n",
    ")\n",
    "\n",
    "\n",
    "# Init population of controllers\n",
    "\n",
    "# maybe consider adding two random keys for each policy\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "keys = jax.random.split(subkey, num=config.batch_size)\n",
    "#split_keys = jax.vmap(lambda k: jax.random.split(k, 2))(keys)\n",
    "#keys1, keys2 = split_keys[:, 0], split_keys[:, 1]\n",
    "fake_batch_obs = jnp.zeros(shape=(config.batch_size, env.observation_size))\n",
    "init_params = jax.vmap(policy_network.init)(keys, fake_batch_obs)\n",
    "\n",
    "param_count = sum(x[0].size for x in jax.tree_util.tree_leaves(init_params))\n",
    "print(\"Number of parameters in policy_network: \", param_count)\n",
    "\n",
    "# Define the fonction to play a step with the policy in the environment\n",
    "def play_step_fn(env_state, policy_params, random_key):\n",
    "    #random_key, subkey = jax.random.split(random_key)\n",
    "    actions = policy_network.apply(policy_params, env_state.obs)\n",
    "    state_desc = env_state.info[\"state_descriptor\"]\n",
    "    next_state = env.step(env_state, actions)\n",
    "\n",
    "    transition = QDTransition(\n",
    "        obs=env_state.obs,\n",
    "        next_obs=next_state.obs,\n",
    "        rewards=next_state.reward,\n",
    "        dones=next_state.done,\n",
    "        truncations=next_state.info[\"truncation\"],\n",
    "        actions=actions,\n",
    "        state_desc=state_desc,\n",
    "        next_state_desc=next_state.info[\"state_descriptor\"],\n",
    "        #desc=jnp.zeros(env.behavior_descriptor_length,) * jnp.nan,\n",
    "        #desc_prime=jnp.zeros(env.behavior_descriptor_length,) * jnp.nan,\n",
    "    )\n",
    "\n",
    "    return next_state, policy_params, random_key, transition\n",
    "\n",
    "# Prepare the scoring function\n",
    "bd_extraction_fn = behavior_descriptor_extractor['ant_uni']\n",
    "scoring_fn = partial(\n",
    "    scoring_function,\n",
    "    episode_length=env.episode_length,\n",
    "    play_reset_fn=reset_fn,\n",
    "    play_step_fn=play_step_fn,\n",
    "    behavior_descriptor_extractor=bd_extraction_fn,\n",
    ")\n",
    "#reward_offset = get_reward_offset_brax(env, config.env_name)\n",
    "#print(f\"Reward offset: {reward_offset}\")\n",
    "\n",
    "me_scoring_fn = partial(\n",
    "sampling,\n",
    "scoring_fn=scoring_fn,\n",
    "num_samples=config.num_samples,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "reward_offset = 0\n",
    "\n",
    "\n",
    "\n",
    "# Get minimum reward value to make sure qd_score are positive\n",
    "\n",
    "\n",
    "# Define a metrics function\n",
    "    # Define a metrics function\n",
    "metrics_function = partial(\n",
    "    default_qd_metrics,\n",
    "    qd_offset=reward_offset * config.env.episode_length,\n",
    ")\n",
    "\n",
    "# Define the PG-emitter config\n",
    "\n",
    "me_mcpg_config = MEMCPGConfig(\n",
    "    proportion_mutation_ga=config.proportion_mutation_ga,\n",
    "    no_agents=config.no_agents,\n",
    "    batch_size=config.batch_size,\n",
    "    mini_batch_size=config.mini_batch_size,\n",
    "    no_epochs=config.no_epochs,\n",
    "    buffer_size=config.buffer_size,\n",
    "    learning_rate=config.learning_rate,\n",
    "    adam_optimizer=config.adam_optimizer,\n",
    "    clip_param=config.clip_param,\n",
    ")\n",
    "\n",
    "variation_fn = partial(\n",
    "    isoline_variation, iso_sigma=config.iso_sigma, line_sigma=config.line_sigma\n",
    ")\n",
    "\n",
    "me_mcpg_emitter = MEMCPGEmitter(\n",
    "    config=me_mcpg_config,\n",
    "    policy_network=policy_network,\n",
    "    env=env,\n",
    "    variation_fn=variation_fn,\n",
    "    )\n",
    "\n",
    "'''\n",
    "rein_emitter = REINaiveEmitter(\n",
    "    config=rein_emitter_config,\n",
    "    policy_network=policy_network,\n",
    "    env=env,\n",
    "    )\n",
    "'''\n",
    "'''\n",
    "me_scoring_fn = partial(\n",
    "    sampling,\n",
    "    scoring_fn=scoring_fn,\n",
    "    num_samples=config.num_samples,\n",
    ")\n",
    "'''\n",
    "\n",
    "# Instantiate MAP Elites\n",
    "map_elites = MAPElites(\n",
    "    scoring_function=scoring_fn,\n",
    "    emitter=me_mcpg_emitter,\n",
    "    metrics_function=metrics_function,\n",
    ")\n",
    "\n",
    "# compute initial repertoire\n",
    "repertoire, emitter_state, random_key = map_elites.init(init_params, centroids, random_key)\n",
    "\n",
    "log_period = 1\n",
    "num_loops = int(config.num_iterations / log_period)\n",
    "\n",
    "\n",
    "# Main loop\n",
    "map_elites_scan_update = map_elites.scan_update\n",
    "'''\n",
    "for i in range(num_loops):\n",
    "    print(f\"Loop {i+1}/{num_loops}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    (repertoire, emitter_state, random_key,), current_metrics = jax.lax.scan(\n",
    "        map_elites_scan_update,\n",
    "        (repertoire, emitter_state, random_key),\n",
    "        (),\n",
    "        length=log_period,\n",
    "    )\n",
    "    timelapse = time.time() - start_time\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length : 20\n",
      "reward*mask shape: (1, 20)\n"
     ]
    }
   ],
   "source": [
    "repertoire, emitter_state, metrics, random_key = map_elites.update(repertoire, emitter_state, random_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = emitter_state.emitter_states[0].trajectory_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.5135491 ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.5104991 ,  1.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.50859904,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.4783475 ,  0.9828977 ,  0.18337119, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.6665856 ,  0.9911529 , -0.00221902, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.5599    ,  0.98609835, -0.04763195, ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 75)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data[jnp.array(x.episodic_data[0], dtype=int)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[  0.,  10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100.,\n",
       "        110., 120., 130., 140., 150., 160., 170., 180., 190.],\n",
       "       [  1.,  11.,  21.,  31.,  41.,  51.,  61.,  71.,  81.,  91., 101.,\n",
       "        111., 121., 131., 141., 151., 161., 171., 181., 191.],\n",
       "       [  2.,  12.,  22.,  32.,  42.,  52.,  62.,  72.,  82.,  92., 102.,\n",
       "        112., 122., 132., 142., 152., 162., 172., 182., 192.],\n",
       "       [  3.,  13.,  23.,  33.,  43.,  53.,  63.,  73.,  83.,  93., 103.,\n",
       "        113., 123., 133., 143., 153., 163., 173., 183., 193.],\n",
       "       [  4.,  14.,  24.,  34.,  44.,  54.,  64.,  74.,  84.,  94., 104.,\n",
       "        114., 124., 134., 144., 154., 164., 174., 184., 194.],\n",
       "       [  5.,  15.,  25.,  35.,  45.,  55.,  65.,  75.,  85.,  95., 105.,\n",
       "        115., 125., 135., 145., 155., 165., 175., 185., 195.],\n",
       "       [  6.,  16.,  26.,  36.,  46.,  56.,  66.,  76.,  86.,  96., 106.,\n",
       "        116., 126., 136., 146., 156., 166., 176., 186., 196.],\n",
       "       [  7.,  17.,  27.,  37.,  47.,  57.,  67.,  77.,  87.,  97., 107.,\n",
       "        117., 127., 137., 147., 157., 167., 177., 187., 197.],\n",
       "       [  8.,  18.,  28.,  38.,  48.,  58.,  68.,  78.,  88.,  98., 108.,\n",
       "        118., 128., 138., 148., 158., 168., 178., 188., 198.],\n",
       "       [  9.,  19.,  29.,  39.,  49.,  59.,  69.,  79.,  89.,  99., 109.,\n",
       "        119., 129., 139., 149., 159., 169., 179., 189., 199.],\n",
       "       [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan]],      dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.episodic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "l = int(x.current_episodic_data_size)\n",
    "print(type(l))\n",
    "\n",
    "r = x.sample_with_returns(rng, 3, episodic_data_size=l, sample_traj=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = r[0].dones.reshape(3, 10, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = 1. - jnp.clip(jnp.cumsum(r[0].dones), a_min=0., a_max=1.)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = r[0].obs.reshape(3, 10, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_trans = r[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 75)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.7246356, 0.7246356, 0.7246356, 0.7246356, 0.7246356, 0.7246356,\n",
       "       0.7246356, 0.7246356, 0.7246356, 0.7246356, 6.0819583, 6.0819583,\n",
       "       6.0819583, 6.0819583, 6.0819583, 6.0819583, 6.0819583, 6.0819583,\n",
       "       6.0819583, 6.0819583, 1.0134742, 1.0134742, 1.0134742, 1.0134742,\n",
       "       1.0134742, 1.0134742, 1.0134742, 1.0134742, 1.0134742, 1.0134742],      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[  nan,   nan,   nan, ...,   nan,   nan,   nan],\n",
       "       [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n",
       "       [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n",
       "       ...,\n",
       "       [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n",
       "       [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n",
       "       [9009., 9019., 9029., ...,   nan,   nan,   nan]],      dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.episodic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(10)\n",
    "\n",
    "e = x.sample_with_returns(rng, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_trans = e[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 75)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ArrayImpl' object has no attribute 'masks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasks\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ArrayImpl' object has no attribute 'masks'"
     ]
    }
   ],
   "source": [
    "x.data.masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode length: 20\n",
      "\n",
      "Environment batch size: 10\n",
      "\n",
      "Number of trajectories: 20\n",
      "\n",
      "Current position: 200\n",
      "\n",
      "Current size: 200\n",
      "\n",
      "Trajectory positions: [1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Timestep positions: [0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Episodic data: [[  0.  10.  20.  30.  40.  50.  60.  70.  80.  90. 100. 110. 120. 130.\n",
      "  140. 150. 160. 170. 180. 190.]\n",
      " [  1.  11.  21.  31.  41.  51.  61.  71.  81.  91. 101. 111. 121. 131.\n",
      "  141. 151. 161. 171. 181. 191.]\n",
      " [  2.  12.  22.  32.  42.  52.  62.  72.  82.  92. 102. 112. 122. 132.\n",
      "  142. 152. 162. 172. 182. 192.]\n",
      " [  3.  13.  23.  33.  43.  53.  63.  73.  83.  93. 103. 113. 123. 133.\n",
      "  143. 153. 163. 173. 183. 193.]\n",
      " [  4.  14.  24.  34.  44.  54.  64.  74.  84.  94. 104. 114. 124. 134.\n",
      "  144. 154. 164. 174. 184. 194.]\n",
      " [  5.  15.  25.  35.  45.  55.  65.  75.  85.  95. 105. 115. 125. 135.\n",
      "  145. 155. 165. 175. 185. 195.]\n",
      " [  6.  16.  26.  36.  46.  56.  66.  76.  86.  96. 106. 116. 126. 136.\n",
      "  146. 156. 166. 176. 186. 196.]\n",
      " [  7.  17.  27.  37.  47.  57.  67.  77.  87.  97. 107. 117. 127. 137.\n",
      "  147. 157. 167. 177. 187. 197.]\n",
      " [  8.  18.  28.  38.  48.  58.  68.  78.  88.  98. 108. 118. 128. 138.\n",
      "  148. 158. 168. 178. 188. 198.]\n",
      " [  9.  19.  29.  39.  49.  59.  69.  79.  89.  99. 109. 119. 129. 139.\n",
      "  149. 159. 169. 179. 189. 199.]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "   nan  nan  nan  nan  nan  nan]]\n",
      "\n",
      "Current episodic data size: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Episode length: {x.episode_length}\\n\")\n",
    "print(f\"Environment batch size: {x.env_batch_size}\\n\")\n",
    "print(f\"Number of trajectories: {x.num_trajectories}\\n\")\n",
    "\n",
    "print(f\"Current position: {x.current_position}\\n\")\n",
    "print(f\"Current size: {x.current_size}\\n\")\n",
    "print(f\"Trajectory positions: {x.trajectory_positions}\\n\")\n",
    "print(f\"Timestep positions: {x.timestep_positions}\\n\")\n",
    "print(f\"Episodic data: {x.episodic_data}\\n\")\n",
    "print(f\"Current episodic data size: {int(x.current_episodic_data_size)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(10, dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.current_episodic_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dones : [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Flattened transitions shape: (array(10, dtype=int32), array(75, dtype=int32))\n",
      "Dones: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "repertoire, emitter_state, metrics, random_key = map_elites.update(repertoire, emitter_state, random_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = emitter_state.emitter_states[0].trajectory_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode length: 20\n",
      "\n",
      "Environment batch size: 10\n",
      "\n",
      "Number of trajectories: 20\n",
      "\n",
      "Current position: 0\n",
      "\n",
      "Current size: 400\n",
      "\n",
      "Trajectory positions: [2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "Timestep positions: [0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Episodic data: [[  0.  10.  20.  30.  40.  50.  60.  70.  80.  90. 100. 110. 120. 130.\n",
      "  140. 150. 160. 170. 180. 190.]\n",
      " [  1.  11.  21.  31.  41.  51.  61.  71.  81.  91. 101. 111. 121. 131.\n",
      "  141. 151. 161. 171. 181. 191.]\n",
      " [  2.  12.  22.  32.  42.  52.  62.  72.  82.  92. 102. 112. 122. 132.\n",
      "  142. 152. 162. 172. 182. 192.]\n",
      " [  3.  13.  23.  33.  43.  53.  63.  73.  83.  93. 103. 113. 123. 133.\n",
      "  143. 153. 163. 173. 183. 193.]\n",
      " [  4.  14.  24.  34.  44.  54.  64.  74.  84.  94. 104. 114. 124. 134.\n",
      "  144. 154. 164. 174. 184. 194.]\n",
      " [  5.  15.  25.  35.  45.  55.  65.  75.  85.  95. 105. 115. 125. 135.\n",
      "  145. 155. 165. 175. 185. 195.]\n",
      " [  6.  16.  26.  36.  46.  56.  66.  76.  86.  96. 106. 116. 126. 136.\n",
      "  146. 156. 166. 176. 186. 196.]\n",
      " [  7.  17.  27.  37.  47.  57.  67.  77.  87.  97. 107. 117. 127. 137.\n",
      "  147. 157. 167. 177. 187. 197.]\n",
      " [  8.  18.  28.  38.  48.  58.  68.  78.  88.  98. 108. 118. 128. 138.\n",
      "  148. 158. 168. 178. 188. 198.]\n",
      " [  9.  19.  29.  39.  49.  59.  69.  79.  89.  99. 109. 119. 129. 139.\n",
      "  149. 159. 169. 179. 189. 199.]\n",
      " [200. 210. 220. 230. 240. 250. 260. 270. 280. 290. 300. 310. 320. 330.\n",
      "  340. 350. 360. 370. 380. 390.]\n",
      " [201. 211. 221. 231. 241. 251. 261. 271. 281. 291. 301. 311. 321. 331.\n",
      "  341. 351. 361. 371. 381. 391.]\n",
      " [202. 212. 222. 232. 242. 252. 262. 272. 282. 292. 302. 312. 322. 332.\n",
      "  342. 352. 362. 372. 382. 392.]\n",
      " [203. 213. 223. 233. 243. 253. 263. 273. 283. 293. 303. 313. 323. 333.\n",
      "  343. 353. 363. 373. 383. 393.]\n",
      " [204. 214. 224. 234. 244. 254. 264. 274. 284. 294. 304. 314. 324. 334.\n",
      "  344. 354. 364. 374. 384. 394.]\n",
      " [205. 215. 225. 235. 245. 255. 265. 275. 285. 295. 305. 315. 325. 335.\n",
      "  345. 355. 365. 375. 385. 395.]\n",
      " [206. 216. 226. 236. 246. 256. 266. 276. 286. 296. 306. 316. 326. 336.\n",
      "  346. 356. 366. 376. 386. 396.]\n",
      " [207. 217. 227. 237. 247. 257. 267. 277. 287. 297. 307. 317. 327. 337.\n",
      "  347. 357. 367. 377. 387. 397.]\n",
      " [208. 218. 228. 238. 248. 258. 268. 278. 288. 298. 308. 318. 328. 338.\n",
      "  348. 358. 368. 378. 388. 398.]\n",
      " [209. 219. 229. 239. 249. 259. 269. 279. 289. 299. 309. 319. 329. 339.\n",
      "  349. 359. 369. 379. 389. 399.]]\n",
      "\n",
      "Current episodic data size: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Episode length: {x.episode_length}\\n\")\n",
    "print(f\"Environment batch size: {x.env_batch_size}\\n\")\n",
    "print(f\"Number of trajectories: {x.num_trajectories}\\n\")\n",
    "\n",
    "print(f\"Current position: {x.current_position}\\n\")\n",
    "print(f\"Current size: {x.current_size}\\n\")\n",
    "print(f\"Trajectory positions: {x.trajectory_positions}\\n\")\n",
    "print(f\"Timestep positions: {x.timestep_positions}\\n\")\n",
    "print(f\"Episodic data: {x.episodic_data}\\n\")\n",
    "print(f\"Current episodic data size: {x.current_episodic_data_size}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transition.dones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
